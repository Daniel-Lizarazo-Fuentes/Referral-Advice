{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "k_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 897 entries, 0 to 1545\n",
      "Data columns (total 37 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Treatment                         897 non-null    int64  \n",
      " 1   Fever                             879 non-null    float64\n",
      " 2   Duration_of_pain                  877 non-null    float64\n",
      " 3   Sick_leave                        897 non-null    int64  \n",
      " 4   Earlier_hospitalization           897 non-null    int64  \n",
      " 5   Workoverload                      255 non-null    float64\n",
      " 6   Familiy_history                   897 non-null    int64  \n",
      " 7   Depression                        897 non-null    int64  \n",
      " 8   Extremely_nervous                 862 non-null    float64\n",
      " 9   Stress                            897 non-null    int64  \n",
      " 10  Relationship_with_colleagues      581 non-null    float64\n",
      " 11  Irrational_thoughts_risk_lasting  857 non-null    float64\n",
      " 12  Irrational_thoughts_work          785 non-null    float64\n",
      " 13  Coping_strategy                   851 non-null    float64\n",
      " 14  Kinesiophobia_physical_exercise   866 non-null    float64\n",
      " 15  Kinesiophobia_pain_stop           855 non-null    float64\n",
      " 16  Age                               897 non-null    object \n",
      " 17  Uses_analgesics                   897 non-null    int64  \n",
      " 18  Uses_corticosteroids              888 non-null    float64\n",
      " 19  Serious_disease                   892 non-null    float64\n",
      " 20  Neurogenic_signals                897 non-null    int64  \n",
      " 21  Continuous_pain                   897 non-null    int64  \n",
      " 22  Decreased_mobility                897 non-null    int64  \n",
      " 23  Nocturnal_pain                    897 non-null    int64  \n",
      " 24  Weightloss_per_year               874 non-null    float64\n",
      " 25  Loss_muscle_strength              859 non-null    float64\n",
      " 26  Trauma                            456 non-null    float64\n",
      " 27  Failure_symptoms                  897 non-null    int64  \n",
      " 28  Incoordination                    778 non-null    float64\n",
      " 29  neck_pain_intensity               897 non-null    int64  \n",
      " 30  low_back_pain_intensity           897 non-null    int64  \n",
      " 31  arm_left_pain_intensity           897 non-null    int64  \n",
      " 32  arm_right_pain_intensity          897 non-null    int64  \n",
      " 33  leg_left_pain_intensity           897 non-null    int64  \n",
      " 34  leg_right_pain_intensity          897 non-null    int64  \n",
      " 35  working_ability                   303 non-null    float64\n",
      " 36  Paidwork                          897 non-null    int64  \n",
      "dtypes: float64(17), int64(19), object(1)\n",
      "memory usage: 266.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "xls = pd.ExcelFile('Dataset - LBP RA.xlsx')\n",
    "dataframe = pd.read_excel(xls, 'Training Dataset')\n",
    "#dataframe = dataframe[(dataframe[\"Treatment\"] == 1) | (dataframe[\"Treatment\"] == 5)]\n",
    "dataframe = dataframe[(dataframe[\"Treatment\"] != 5)]\n",
    "dataframe_original = dataframe.copy(True)\n",
    "print(dataframe.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"Treatment\", \"Weightloss_per_year\"]\n",
    "\n",
    "boolean_columns = [\n",
    "    \"Fever\",\n",
    "    \"Sick_leave\",\n",
    "    \"Earlier_hospitalization\",\n",
    "    \"Workoverload\",\n",
    "    \"Familiy_history\",\n",
    "    \"Depression\",\n",
    "    \"Stress\",\n",
    "    \"Uses_analgesics\",\n",
    "    \"Uses_corticosteroids\",\n",
    "    \"Serious_disease\",\n",
    "    \"Neurogenic_signals\",\n",
    "    \"Continuous_pain\",\n",
    "    \"Nocturnal_pain\",\n",
    "    \"Loss_muscle_strength\",\n",
    "    \"Trauma\",\n",
    "    \"Failure_symptoms\",\n",
    "    \"Incoordination\",\n",
    "    \"Paidwork\",\n",
    "]\n",
    "\n",
    "ordinal_columns = [\n",
    "    \"Duration_of_pain\",\n",
    "    \"Extremely_nervous\",\n",
    "    \"Relationship_with_colleagues\",\n",
    "    \"Irrational_thoughts_risk_lasting\",\n",
    "    \"Irrational_thoughts_work\",\n",
    "    \"Coping_strategy\",\n",
    "    \"Kinesiophobia_physical_exercise\",\n",
    "    \"Kinesiophobia_pain_stop\",\n",
    "    \"Age\",\n",
    "    \"neck_pain_intensity\",\n",
    "    \"low_back_pain_intensity\",\n",
    "    \"arm_left_pain_intensity\",\n",
    "    \"arm_right_pain_intensity\",\n",
    "    \"leg_left_pain_intensity\",\n",
    "    \"leg_right_pain_intensity\",\n",
    "    \"working_ability\",\n",
    "]\n",
    "\n",
    "value_columns = [\"Decreased_mobility\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping integer colum\n",
    "dataframe[value_columns] = dataframe[value_columns].astype(\"Int64\")\n",
    "\n",
    "# Mapping categories and boolean columns\n",
    "dataframe[categorical_columns] = dataframe[categorical_columns].astype(\"category\")\n",
    "dataframe[boolean_columns] = dataframe[boolean_columns].astype(\"boolean\")\n",
    "\n",
    "# Mapping ordinal columns \n",
    "age_mapping = {\n",
    "    \"0-19\": 0,\n",
    "    \"20-29\": 1,\n",
    "    \"30-39\": 2,\n",
    "    \"40-49\": 3,\n",
    "    \"50-59\": 4,\n",
    "    \"60-69\": 5,\n",
    "    \"70-79\": 6,\n",
    "    \">=80\": 7,\n",
    "}\n",
    "\n",
    "dataframe[\"Age\"] = dataframe[\"Age\"].replace(age_mapping)\n",
    "\n",
    "for column in ordinal_columns:\n",
    "    dataframe[[column]] = dataframe[[column]].astype(\"Int64\")\n",
    "    dataframe[column].fillna(-1, inplace=True)\n",
    "    dataframe[column] = pd.Categorical(dataframe[column], categories=sorted(dataframe[column].unique()), ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy: 0.6402 (+/- 0.3847)\n",
      "Gradient Boosting: Accuracy: 0.6146 (+/- 0.3827)\n",
      "KNN: Accuracy: 0.7001 (+/- 0.0286)\n",
      "Logistic Regression: Accuracy: 0.6135 (+/- 0.3886)\n",
      "Neural Network: Accuracy: 0.5722 (+/- 0.3053)\n",
      "SVM: Accuracy: 0.7347 (+/- 0.0046)\n",
      "Average Accuracy Across All Models: 0.6459\n",
      "Ensemble Model (Voting): Accuracy: 0.6747 (+/- 0.2304)\n"
     ]
    }
   ],
   "source": [
    "missing_percentages = dataframe_original.isnull().mean()\n",
    "columns_to_remove = missing_percentages[missing_percentages > 0.7].index.tolist()\n",
    "dataframe = dataframe.drop(columns=columns_to_remove)\n",
    "\n",
    "categorical_columns = [\n",
    "    col for col in categorical_columns if col not in columns_to_remove\n",
    "]\n",
    "ordinal_columns = [col for col in ordinal_columns if col not in columns_to_remove]\n",
    "boolean_columns = [col for col in boolean_columns if col not in columns_to_remove]\n",
    "value_columns = [col for col in value_columns if col not in columns_to_remove]\n",
    "\n",
    "X = dataframe.drop(columns=[\"Treatment\"])\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "y = dataframe[\"Treatment\"]\n",
    "\n",
    "minority_data = dataframe[(dataframe[\"Treatment\"] != 1) & (dataframe[\"Treatment\"] != 5)]\n",
    "minority_data = pd.concat([minority_data] * 3)\n",
    "minority_X = minority_data.drop(columns=[\"Treatment\"])\n",
    "minority_y = minority_data[\"Treatment\"]\n",
    "train_X = imputer.fit_transform(pd.concat([minority_X, X], axis=0))\n",
    "train_y = pd.concat([minority_y, y], axis=0)\n",
    "\n",
    "models = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier().fit(train_X, train_y)),\n",
    "    (\"Random Forest\", OneVsRestClassifier(RandomForestClassifier()).fit(train_X, train_y)),\n",
    "    (\"Gradient Boosting\", OneVsRestClassifier(HistGradientBoostingClassifier()).fit(train_X, train_y)),\n",
    "    (\"KNN\", KNeighborsClassifier().fit(train_X, train_y)),\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=4000, solver='saga').fit(train_X, train_y)), \n",
    "    (\"Neural Network\", MLPClassifier(max_iter=4000).fit(train_X, train_y)),\n",
    "    (\"SVM\",SVC().fit(train_X, train_y)) \n",
    "]\n",
    "\n",
    "model_scores = {}\n",
    "\n",
    "for name, model in models:\n",
    "    scores = cross_val_score(model, X_imputed, y, cv=k_folds, scoring=\"accuracy\")\n",
    "    model_scores[name] = scores\n",
    "    print(f\"{name}: Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "\n",
    "average_accuracy = np.mean([scores.mean() for scores in model_scores.values()])\n",
    "print(f\"Average Accuracy Across All Models: {average_accuracy:.4f}\")\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=models, voting=\"hard\")\n",
    "scores = cross_val_score(ensemble_model, X_imputed, y, scoring=\"accuracy\")\n",
    "\n",
    "print(f\"Ensemble Model (Voting): Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_encoded = pd.get_dummies(dataframe[categorical_columns], drop_first=True)\n",
    "# X = pd.concat(\n",
    "#     [dataframe[value_columns + ordinal_columns + boolean_columns], X_encoded], axis=1\n",
    "# )\n",
    "# X_clean = X.dropna()\n",
    "\n",
    "# y = dataframe[\"Treatment\"]\n",
    "# y_clean = y[X.index.isin(X_clean.index)]\n",
    "\n",
    "# minority_data = dataframe[(dataframe[\"Treatment\"] != 1) & (dataframe[\"Treatment\"] != 5)]\n",
    "# minority_data = pd.concat([minority_data] * 3)\n",
    "# minority_X_encoded = pd.get_dummies(minority_data[categorical_columns], drop_first=True)\n",
    "# minority_X = pd.concat(\n",
    "#     [\n",
    "#         minority_data[value_columns + ordinal_columns + boolean_columns],\n",
    "#         minority_X_encoded,\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )\n",
    "# minority_X_clean = minority_X.dropna()\n",
    "\n",
    "# minority_y = minority_data[\"Treatment\"]\n",
    "# minority_y_clean = minority_y[minority_X.index.isin(minority_X_clean.index)]\n",
    "\n",
    "\n",
    "# X_Train = pd.concat([X_clean, minority_X_clean], axis=0)\n",
    "# y_Train = pd.concat([y_clean, minority_y_clean], axis=0)\n",
    "\n",
    "# # print(y_clean.info())\n",
    "# # print(y_Train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Decision Tree Model\n",
    "# param_grid = {\n",
    "#     \"max_depth\": [1, 2, 3, 4, 5, 10],\n",
    "#     \"min_samples_split\": [2, 5, 10],\n",
    "#     \"min_samples_leaf\": [1, 2, 4],\n",
    "# }\n",
    "# grid_search = GridSearchCV(\n",
    "#     DecisionTreeClassifier(), param_grid, cv=cv, scoring=\"accuracy\"\n",
    "# )\n",
    "# grid_search.fit(X_Train, y_Train)\n",
    "# best_params = grid_search.best_params_\n",
    "# # print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# best_max_depth = grid_search.best_params_[\"max_depth\"]\n",
    "# best_min_samples_split = grid_search.best_params_[\"min_samples_split\"]\n",
    "# best_min_samples_leaf = grid_search.best_params_[\"min_samples_leaf\"]\n",
    "\n",
    "# tree_model = DecisionTreeClassifier(\n",
    "#     max_depth=best_max_depth,\n",
    "#     min_samples_split=best_min_samples_split,\n",
    "#     min_samples_leaf=best_min_samples_leaf,\n",
    "# )\n",
    "\n",
    "# tree_model.fit(X_Train, y_Train)\n",
    "# tree_predicted = cross_val_predict(tree_model, X, y, cv=cv)\n",
    "\n",
    "# # Evaluation\n",
    "# print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "# print(\"Decision Tree Model:\")\n",
    "# print(classification_report(y, tree_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_labels = [str(label) for label in tree_model.classes_]\n",
    "# plt.figure(figsize=(135, 90))\n",
    "# plot_tree(tree_model,max_depth=5, feature_names=X.columns, class_names=class_labels, filled=True, rounded=True)\n",
    "# plt.show()\n",
    "\n",
    "# Note that colors are based on the majority class in a leaf (with intensity being an indicator for how large this majority is over the others)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Histogram-based Gradient Boosting Classification Tree Model\n",
    "# boosting_model = HistGradientBoostingClassifier(max_depth=5)\n",
    "# boosting_model.fit(X_Train, y_Train)\n",
    "# boosting_predicted = cross_val_predict(boosting_model, X, y, cv=cv)\n",
    "\n",
    "# # Evaluation\n",
    "# print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "# print(\"Histogram-based Gradient Boosting Classification Tree Model:\")\n",
    "# print(classification_report(y, boosting_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random forest model\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "# rf_model.fit(X_Train, y_Train)\n",
    "# rf_predicted = cross_val_predict(rf_model, X_clean, y_clean, cv=cv)\n",
    "\n",
    "# # Evaluation\n",
    "# print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "# print(\"Random forest model:\")\n",
    "# print(classification_report(y_clean, rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # KNN model\n",
    "# knn_model = KNeighborsClassifier(n_neighbors=7)  \n",
    "# knn_model.fit(X_Train, y_Train)\n",
    "# knn_predicted = cross_val_predict(knn_model, X_clean, y_clean, cv=cv)\n",
    "\n",
    "# # Evaluation\n",
    "# print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "# print(\"K-Nearest Neighbors model:\")\n",
    "# print(classification_report(y_clean, knn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensemble model - Duplication\n",
    "# ensemble_model = VotingClassifier(estimators=[\n",
    "#     ('decision_tree', tree_model),\n",
    "#     ('gradient_boosting', boosting_model),\n",
    "#     ('random_forest', rf_model)\n",
    "#     ,('knn',knn_model)\n",
    "# ], voting='hard')\n",
    "\n",
    "# ensemble_predicted = cross_val_predict(ensemble_model, X_clean, y_clean, cv=cv)\n",
    "\n",
    "# print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "# print(\"Ensemble Model:\")\n",
    "# print(classification_report(y_clean, ensemble_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensemble model - No duplication\n",
    "# # ------------------------------------------------------------------------\n",
    "# # Decision Tree Model\n",
    "# param_grid = {\n",
    "#     \"max_depth\": [1, 2, 3, 4, 5, 10],\n",
    "#     \"min_samples_split\": [2, 5, 10],\n",
    "#     \"min_samples_leaf\": [1, 2, 4],\n",
    "# }\n",
    "# grid_search = GridSearchCV(\n",
    "#     DecisionTreeClassifier(), param_grid, cv=cv, scoring=\"accuracy\"\n",
    "# )\n",
    "# grid_search.fit(X, y)\n",
    "# best_params = grid_search.best_params_\n",
    "# # print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# best_max_depth = grid_search.best_params_[\"max_depth\"]\n",
    "# best_min_samples_split = grid_search.best_params_[\"min_samples_split\"]\n",
    "# best_min_samples_leaf = grid_search.best_params_[\"min_samples_leaf\"]\n",
    "\n",
    "# tree_model = DecisionTreeClassifier(\n",
    "#     max_depth=best_max_depth,\n",
    "#     min_samples_split=best_min_samples_split,\n",
    "#     min_samples_leaf=best_min_samples_leaf,\n",
    "# )\n",
    "\n",
    "# tree_model.fit(X_clean, y_clean)\n",
    "# # ------------------------------------------------------------------------\n",
    "# # Random forest model\n",
    "# rf_model = RandomForestClassifier(max_depth=5)\n",
    "# rf_model.fit(X_clean, y_clean)\n",
    "# # ------------------------------------------------------------------------\n",
    "# # Histogram-based Gradient Boosting Classification Tree Model\n",
    "# boosting_model = HistGradientBoostingClassifier(max_depth=5)\n",
    "# boosting_model.fit(X_clean, y_clean)\n",
    "# # ------------------------------------------------------------------------\n",
    "\n",
    "# ensemble_model = VotingClassifier(estimators=[\n",
    "#     ('decision_tree', tree_model),\n",
    "#     ('gradient_boosting', boosting_model),\n",
    "#     ('random_forest', rf_model)\n",
    "# ], voting='hard')\n",
    "\n",
    "# ensemble_predicted = cross_val_predict(ensemble_model, X_clean, y_clean, cv=cv)\n",
    "\n",
    "# print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "# print(\"Ensemble Model:\")\n",
    "# print(classification_report(y_clean, ensemble_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

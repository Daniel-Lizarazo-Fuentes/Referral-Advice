{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1546 entries, 0 to 1545\n",
      "Data columns (total 37 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Treatment                         1546 non-null   int64  \n",
      " 1   Fever                             1512 non-null   float64\n",
      " 2   Duration_of_pain                  1515 non-null   float64\n",
      " 3   Sick_leave                        1546 non-null   int64  \n",
      " 4   Earlier_hospitalization           1546 non-null   int64  \n",
      " 5   Workoverload                      459 non-null    float64\n",
      " 6   Familiy_history                   1546 non-null   int64  \n",
      " 7   Depression                        1546 non-null   int64  \n",
      " 8   Extremely_nervous                 1494 non-null   float64\n",
      " 9   Stress                            1546 non-null   int64  \n",
      " 10  Relationship_with_colleagues      979 non-null    float64\n",
      " 11  Irrational_thoughts_risk_lasting  1475 non-null   float64\n",
      " 12  Irrational_thoughts_work          1363 non-null   float64\n",
      " 13  Coping_strategy                   1476 non-null   float64\n",
      " 14  Kinesiophobia_physical_exercise   1495 non-null   float64\n",
      " 15  Kinesiophobia_pain_stop           1478 non-null   float64\n",
      " 16  Age                               1546 non-null   object \n",
      " 17  Uses_analgesics                   1546 non-null   int64  \n",
      " 18  Uses_corticosteroids              1533 non-null   float64\n",
      " 19  Serious_disease                   1534 non-null   float64\n",
      " 20  Neurogenic_signals                1546 non-null   int64  \n",
      " 21  Continuous_pain                   1546 non-null   int64  \n",
      " 22  Decreased_mobility                1546 non-null   int64  \n",
      " 23  Nocturnal_pain                    1546 non-null   int64  \n",
      " 24  Weightloss_per_year               1509 non-null   float64\n",
      " 25  Loss_muscle_strength              1464 non-null   float64\n",
      " 26  Trauma                            866 non-null    float64\n",
      " 27  Failure_symptoms                  1546 non-null   int64  \n",
      " 28  Incoordination                    1316 non-null   float64\n",
      " 29  neck_pain_intensity               1546 non-null   int64  \n",
      " 30  low_back_pain_intensity           1546 non-null   int64  \n",
      " 31  arm_left_pain_intensity           1546 non-null   int64  \n",
      " 32  arm_right_pain_intensity          1546 non-null   int64  \n",
      " 33  leg_left_pain_intensity           1546 non-null   int64  \n",
      " 34  leg_right_pain_intensity          1546 non-null   int64  \n",
      " 35  working_ability                   504 non-null    float64\n",
      " 36  Paidwork                          1546 non-null   int64  \n",
      "dtypes: float64(17), int64(19), object(1)\n",
      "memory usage: 447.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "xls = pd.ExcelFile('Dataset - LBP RA.xlsx')\n",
    "dataframe = pd.read_excel(xls, 'Training Dataset')\n",
    "#dataframe = dataframe[(dataframe[\"Treatment\"] == 1) | (dataframe[\"Treatment\"] == 5)]\n",
    "# dataframe = dataframe[(dataframe[\"Treatment\"] != 5)]\n",
    "dataframe_original = dataframe.copy(True)\n",
    "print(dataframe.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"Treatment\", \"Weightloss_per_year\"]\n",
    "\n",
    "boolean_columns = [\n",
    "    \"Fever\",\n",
    "    \"Sick_leave\",\n",
    "    \"Earlier_hospitalization\",\n",
    "    \"Workoverload\",\n",
    "    \"Familiy_history\",\n",
    "    \"Depression\",\n",
    "    \"Stress\",\n",
    "    \"Uses_analgesics\",\n",
    "    \"Uses_corticosteroids\",\n",
    "    \"Serious_disease\",\n",
    "    \"Neurogenic_signals\",\n",
    "    \"Continuous_pain\",\n",
    "    \"Nocturnal_pain\",\n",
    "    \"Loss_muscle_strength\",\n",
    "    \"Trauma\",\n",
    "    \"Failure_symptoms\",\n",
    "    \"Incoordination\",\n",
    "    \"Paidwork\",\n",
    "]\n",
    "\n",
    "ordinal_columns = [\n",
    "    \"Duration_of_pain\",\n",
    "    \"Extremely_nervous\",\n",
    "    \"Relationship_with_colleagues\",\n",
    "    \"Irrational_thoughts_risk_lasting\",\n",
    "    \"Irrational_thoughts_work\",\n",
    "    \"Coping_strategy\",\n",
    "    \"Kinesiophobia_physical_exercise\",\n",
    "    \"Kinesiophobia_pain_stop\",\n",
    "    \"Age\",\n",
    "    \"neck_pain_intensity\",\n",
    "    \"low_back_pain_intensity\",\n",
    "    \"arm_left_pain_intensity\",\n",
    "    \"arm_right_pain_intensity\",\n",
    "    \"leg_left_pain_intensity\",\n",
    "    \"leg_right_pain_intensity\",\n",
    "    \"working_ability\",\n",
    "]\n",
    "\n",
    "value_columns = [\"Decreased_mobility\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping integer colum\n",
    "dataframe[value_columns] = dataframe[value_columns].astype(\"Int64\")\n",
    "\n",
    "# Mapping categories and boolean columns\n",
    "dataframe[categorical_columns] = dataframe[categorical_columns].astype(\"category\")\n",
    "dataframe[boolean_columns] = dataframe[boolean_columns].astype(\"boolean\")\n",
    "\n",
    "# Mapping ordinal columns \n",
    "age_mapping = {\n",
    "    \"0-19\": 0,\n",
    "    \"20-29\": 1,\n",
    "    \"30-39\": 2,\n",
    "    \"40-49\": 3,\n",
    "    \"50-59\": 4,\n",
    "    \"60-69\": 5,\n",
    "    \"70-79\":6,\n",
    "    \">=80\": 7,\n",
    "}\n",
    "\n",
    "dataframe[\"Age\"] = dataframe[\"Age\"].replace(age_mapping)\n",
    "\n",
    "for column in ordinal_columns:\n",
    "    dataframe[[column]] = dataframe[[column]].astype(\"Int64\")\n",
    "    dataframe[column].fillna(-1, inplace=True)\n",
    "    dataframe[column] = pd.Categorical(dataframe[column], categories=sorted(dataframe[column].unique()), ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1546 entries, 0 to 1545\n",
      "Data columns (total 33 columns):\n",
      " #   Column                            Non-Null Count  Dtype   \n",
      "---  ------                            --------------  -----   \n",
      " 0   Treatment                         1546 non-null   category\n",
      " 1   Fever                             1512 non-null   boolean \n",
      " 2   Duration_of_pain                  1546 non-null   category\n",
      " 3   Sick_leave                        1546 non-null   boolean \n",
      " 4   Earlier_hospitalization           1546 non-null   boolean \n",
      " 5   Familiy_history                   1546 non-null   boolean \n",
      " 6   Depression                        1546 non-null   boolean \n",
      " 7   Extremely_nervous                 1546 non-null   category\n",
      " 8   Stress                            1546 non-null   boolean \n",
      " 9   Irrational_thoughts_risk_lasting  1546 non-null   category\n",
      " 10  Irrational_thoughts_work          1546 non-null   category\n",
      " 11  Coping_strategy                   1546 non-null   category\n",
      " 12  Kinesiophobia_physical_exercise   1546 non-null   category\n",
      " 13  Kinesiophobia_pain_stop           1546 non-null   category\n",
      " 14  Age                               1546 non-null   category\n",
      " 15  Uses_analgesics                   1546 non-null   boolean \n",
      " 16  Uses_corticosteroids              1533 non-null   boolean \n",
      " 17  Serious_disease                   1534 non-null   boolean \n",
      " 18  Neurogenic_signals                1546 non-null   boolean \n",
      " 19  Continuous_pain                   1546 non-null   boolean \n",
      " 20  Decreased_mobility                1546 non-null   Int64   \n",
      " 21  Nocturnal_pain                    1546 non-null   boolean \n",
      " 22  Weightloss_per_year               1509 non-null   category\n",
      " 23  Loss_muscle_strength              1464 non-null   boolean \n",
      " 24  Failure_symptoms                  1546 non-null   boolean \n",
      " 25  Incoordination                    1316 non-null   boolean \n",
      " 26  neck_pain_intensity               1546 non-null   category\n",
      " 27  low_back_pain_intensity           1546 non-null   category\n",
      " 28  arm_left_pain_intensity           1546 non-null   category\n",
      " 29  arm_right_pain_intensity          1546 non-null   category\n",
      " 30  leg_left_pain_intensity           1546 non-null   category\n",
      " 31  leg_right_pain_intensity          1546 non-null   category\n",
      " 32  Paidwork                          1546 non-null   boolean \n",
      "dtypes: Int64(1), boolean(16), category(16)\n",
      "memory usage: 91.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "missing_percentages = dataframe_original.isnull().mean()\n",
    "columns_to_remove = missing_percentages[missing_percentages > 0.3].index.tolist()\n",
    "dataframe = dataframe.drop(columns=columns_to_remove)\n",
    "\n",
    "categorical_columns =  [col for col in categorical_columns if col not in columns_to_remove]\n",
    "ordinal_columns = [col for col in ordinal_columns if col not in columns_to_remove]\n",
    "boolean_columns = [col for col in boolean_columns if col not in columns_to_remove]\n",
    "value_columns = [col for col in value_columns if col not in columns_to_remove]\n",
    "\n",
    "print(dataframe.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 1216 entries, 1 to 1545\n",
      "Series name: Treatment\n",
      "Non-Null Count  Dtype   \n",
      "--------------  -----   \n",
      "1216 non-null   category\n",
      "dtypes: category(1)\n",
      "memory usage: 10.9 KB\n",
      "None\n",
      "1    3\n",
      "2    1\n",
      "5    1\n",
      "6    1\n",
      "8    1\n",
      "Name: Treatment, dtype: category\n",
      "Categories (4, int64): [1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "categorical_columns.remove(\"Treatment\")\n",
    "\n",
    "X_encoded = pd.get_dummies(dataframe[categorical_columns], drop_first=True)\n",
    "X = pd.concat(\n",
    "    [dataframe[value_columns + ordinal_columns + boolean_columns], X_encoded], axis=1\n",
    ")\n",
    "X_clean = X.dropna()\n",
    "\n",
    "y = dataframe[\"Treatment\"]\n",
    "y_clean = y[X.index.isin(X_clean.index)]\n",
    "\n",
    "minority_data = dataframe[(dataframe[\"Treatment\"] != 1) & (dataframe[\"Treatment\"] != 5)]\n",
    "minority_data = pd.concat([minority_data] * 3)\n",
    "minority_X_encoded = pd.get_dummies(minority_data[categorical_columns], drop_first=True)\n",
    "minority_X = pd.concat(\n",
    "    [\n",
    "        minority_data[value_columns + ordinal_columns + boolean_columns],\n",
    "        minority_X_encoded,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "minority_X_clean = minority_X.dropna()\n",
    "\n",
    "minority_y = minority_data[\"Treatment\"]\n",
    "minority_y_clean = minority_y[minority_X.index.isin(minority_X_clean.index)]\n",
    "\n",
    "\n",
    "X_Train = pd.concat([X_clean, minority_X_clean], axis=0)\n",
    "y_Train = pd.concat([y_clean, minority_y_clean], axis=0)\n",
    "\n",
    "print(y_clean.info())\n",
    "print(y_Train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple k=5 K fold CV\n",
      "Decision Tree Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.42      0.43       659\n",
      "           2       0.16      0.12      0.14       160\n",
      "           3       0.14      0.06      0.09        65\n",
      "           4       0.00      0.00      0.00        13\n",
      "           5       0.44      0.53      0.48       649\n",
      "\n",
      "    accuracy                           0.41      1546\n",
      "   macro avg       0.24      0.23      0.23      1546\n",
      "weighted avg       0.40      0.41      0.40      1546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Model\n",
    "param_grid = {\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(), param_grid, cv=cv, scoring=\"accuracy\"\n",
    ")\n",
    "grid_search.fit(X_Train, y_Train)\n",
    "best_params = grid_search.best_params_\n",
    "# print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "best_max_depth = grid_search.best_params_[\"max_depth\"]\n",
    "best_min_samples_split = grid_search.best_params_[\"min_samples_split\"]\n",
    "best_min_samples_leaf = grid_search.best_params_[\"min_samples_leaf\"]\n",
    "\n",
    "tree_model = DecisionTreeClassifier(\n",
    "    max_depth=best_max_depth,\n",
    "    min_samples_split=best_min_samples_split,\n",
    "    min_samples_leaf=best_min_samples_leaf,\n",
    ")\n",
    "\n",
    "tree_model.fit(X_Train, y_Train)\n",
    "tree_predicted = cross_val_predict(tree_model, X, y, cv=5)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "print(\"Decision Tree Model:\")\n",
    "print(classification_report(y, tree_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_labels = [str(label) for label in tree_model.classes_]\n",
    "# plt.figure(figsize=(135, 90))\n",
    "# plot_tree(tree_model,max_depth=5, feature_names=X.columns, class_names=class_labels, filled=True, rounded=True)\n",
    "# plt.show()\n",
    "\n",
    "# Note that colors are based on the majority class in a leaf (with intensity being an indicator for how large this majority is over the others)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple k=5 K fold CV\n",
      "Histogram-based Gradient Boosting Classification Tree Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.47      0.46       659\n",
      "           2       0.17      0.07      0.10       160\n",
      "           3       0.07      0.02      0.03        65\n",
      "           4       0.00      0.00      0.00        13\n",
      "           5       0.45      0.55      0.50       649\n",
      "\n",
      "    accuracy                           0.44      1546\n",
      "   macro avg       0.23      0.22      0.22      1546\n",
      "weighted avg       0.40      0.44      0.42      1546\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Histogram-based Gradient Boosting Classification Tree Model\n",
    "boosting_model = HistGradientBoostingClassifier(max_depth=5)\n",
    "boosting_model.fit(X_Train, y_Train)\n",
    "boosting_predicted = cross_val_predict(boosting_model, X, y, cv=cv)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "print(\"Histogram-based Gradient Boosting Classification Tree Model:\")\n",
    "print(classification_report(y, boosting_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple k=5 K fold CV\n",
      "Random forest model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.58      0.52       535\n",
      "           2       1.00      0.01      0.01       133\n",
      "           3       1.00      0.02      0.04        46\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.46      0.51      0.48       492\n",
      "\n",
      "    accuracy                           0.46      1216\n",
      "   macro avg       0.58      0.22      0.21      1216\n",
      "weighted avg       0.54      0.46      0.43      1216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "rf_model.fit(X_Train, y_Train)\n",
    "rf_predicted = cross_val_predict(rf_model, X_clean, y_clean, cv=cv)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "print(\"Random forest model:\")\n",
    "print(classification_report(y_clean, rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple k=5 K fold CV\n",
      "K-Nearest Neighbors model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.60      0.52       535\n",
      "           2       0.10      0.02      0.04       133\n",
      "           3       0.00      0.00      0.00        46\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.42      0.41      0.42       492\n",
      "\n",
      "    accuracy                           0.43      1216\n",
      "   macro avg       0.19      0.21      0.19      1216\n",
      "weighted avg       0.38      0.43      0.40      1216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=7)  \n",
    "knn_model.fit(X_Train, y_Train)\n",
    "knn_predicted = cross_val_predict(knn_model, X_clean, y_clean, cv=cv)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "print(\"K-Nearest Neighbors model:\")\n",
    "print(classification_report(y_clean, knn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[161], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensemble model - Duplication\u001b[39;00m\n\u001b[0;32m      2\u001b[0m ensemble_model \u001b[38;5;241m=\u001b[39m VotingClassifier(estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      3\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecision_tree\u001b[39m\u001b[38;5;124m'\u001b[39m, tree_model),\n\u001b[0;32m      4\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradient_boosting\u001b[39m\u001b[38;5;124m'\u001b[39m, boosting_model),\n\u001b[0;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m'\u001b[39m, rf_model)\n\u001b[0;32m      6\u001b[0m     ,(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m'\u001b[39m,knn_model)\n\u001b[0;32m      7\u001b[0m ], voting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhard\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m ensemble_predicted \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimple k=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(cv) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m K fold CV\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsemble Model:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1033\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m-> 1033\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[0;32m   1038\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1041\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1115\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1115\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1116\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[0;32m   1117\u001b[0m predictions \u001b[38;5;241m=\u001b[39m func(X_test)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:349\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    347\u001b[0m transformed_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:81\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m     )\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVoting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:36\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[1;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m---> 36\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:696\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees_per_iteration_):\n\u001b[0;32m    679\u001b[0m     grower \u001b[38;5;241m=\u001b[39m TreeGrower(\n\u001b[0;32m    680\u001b[0m         X_binned\u001b[38;5;241m=\u001b[39mX_binned_train,\n\u001b[0;32m    681\u001b[0m         gradients\u001b[38;5;241m=\u001b[39mg_view[:, k],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    694\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m    695\u001b[0m     )\n\u001b[1;32m--> 696\u001b[0m     \u001b[43mgrower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    698\u001b[0m     acc_apply_split_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grower\u001b[38;5;241m.\u001b[39mtotal_apply_split_time\n\u001b[0;32m    699\u001b[0m     acc_find_split_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grower\u001b[38;5;241m.\u001b[39mtotal_find_split_time\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\grower.py:366\u001b[0m, in \u001b[0;36mTreeGrower.grow\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Grow the tree, from root to leaves.\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplittable_nodes:\n\u001b[1;32m--> 366\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_shrinkage()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\grower.py:586\u001b[0m, in \u001b[0;36mTreeGrower.split_next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;66;03m# We use the brute O(n_samples) method on the child that has the\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;66;03m# smallest number of samples, and the subtraction trick O(n_bins)\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;66;03m# on the other one.\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;66;03m# Note that both left and right child have the same allowed_features.\u001b[39;00m\n\u001b[0;32m    585\u001b[0m tic \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m--> 586\u001b[0m smallest_child\u001b[38;5;241m.\u001b[39mhistograms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistogram_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_histograms_brute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43msmallest_child\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmallest_child\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallowed_features\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    589\u001b[0m largest_child\u001b[38;5;241m.\u001b[39mhistograms \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_builder\u001b[38;5;241m.\u001b[39mcompute_histograms_subtraction(\n\u001b[0;32m    591\u001b[0m         node\u001b[38;5;241m.\u001b[39mhistograms,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    594\u001b[0m     )\n\u001b[0;32m    595\u001b[0m )\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_compute_hist_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m tic\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ensemble model - Duplication\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('decision_tree', tree_model),\n",
    "    ('gradient_boosting', boosting_model),\n",
    "    ('random_forest', rf_model)\n",
    "    ,('knn',knn_model)\n",
    "], voting='hard')\n",
    "\n",
    "ensemble_predicted = cross_val_predict(ensemble_model, X_clean, y_clean, cv=cv)\n",
    "\n",
    "print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "print(\"Ensemble Model:\")\n",
    "print(classification_report(y_clean, ensemble_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple k=5 K fold CV\n",
      "Ensemble Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.55      0.49       535\n",
      "           2       0.50      0.01      0.01       133\n",
      "           3       0.33      0.02      0.04        46\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.42      0.47      0.44       492\n",
      "\n",
      "    accuracy                           0.43      1216\n",
      "   macro avg       0.34      0.21      0.20      1216\n",
      "weighted avg       0.43      0.43      0.40      1216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Ensemble model - No duplication\n",
    "# ------------------------------------------------------------------------\n",
    "# Decision Tree Model\n",
    "param_grid = {\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(), param_grid, cv=cv, scoring=\"accuracy\"\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "best_params = grid_search.best_params_\n",
    "# print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "best_max_depth = grid_search.best_params_[\"max_depth\"]\n",
    "best_min_samples_split = grid_search.best_params_[\"min_samples_split\"]\n",
    "best_min_samples_leaf = grid_search.best_params_[\"min_samples_leaf\"]\n",
    "\n",
    "tree_model = DecisionTreeClassifier(\n",
    "    max_depth=best_max_depth,\n",
    "    min_samples_split=best_min_samples_split,\n",
    "    min_samples_leaf=best_min_samples_leaf,\n",
    ")\n",
    "\n",
    "tree_model.fit(X_clean, y_clean)\n",
    "# ------------------------------------------------------------------------\n",
    "# Random forest model\n",
    "rf_model = RandomForestClassifier(max_depth=5)\n",
    "rf_model.fit(X_clean, y_clean)\n",
    "# ------------------------------------------------------------------------\n",
    "# Histogram-based Gradient Boosting Classification Tree Model\n",
    "boosting_model = HistGradientBoostingClassifier(max_depth=5)\n",
    "boosting_model.fit(X_clean, y_clean)\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('decision_tree', tree_model),\n",
    "    ('gradient_boosting', boosting_model),\n",
    "    ('random_forest', rf_model)\n",
    "], voting='hard')\n",
    "\n",
    "ensemble_predicted = cross_val_predict(ensemble_model, X_clean, y_clean, cv=cv)\n",
    "\n",
    "print(\"Simple k=\" + str(cv) + \" K fold CV\")\n",
    "print(\"Ensemble Model:\")\n",
    "print(classification_report(y_clean, ensemble_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
